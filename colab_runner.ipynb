{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href=\"https://colab.research.google.com/github/thestbobo/DLML_FL_project/blob/global_mask_fix/colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Environment Setup**"
   ],
   "metadata": {
    "id": "L51bSihQEz-a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "EkDPMfWpSljA",
    "outputId": "506912a8-2257-4976-a15c-84af542d1b58",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f1EUz3AzEYn9",
    "outputId": "163f3540-6122-4a94-f5d0-3c84e7762caa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'DLML_FL_project'...\n",
      "remote: Enumerating objects: 269, done.\u001B[K\n",
      "remote: Counting objects: 100% (167/167), done.\u001B[K\n",
      "remote: Compressing objects: 100% (100/100), done.\u001B[K\n",
      "remote: Total 269 (delta 94), reused 120 (delta 56), pack-reused 102 (from 1)\u001B[K\n",
      "Receiving objects: 100% (269/269), 67.41 KiB | 556.00 KiB/s, done.\n",
      "Resolving deltas: 100% (129/129), done.\n",
      "/content/DLML_FL_project\n"
     ]
    }
   ],
   "source": [
    "# Clone GitHub repository\n",
    "!git clone -b global_mask_fix https://github.com/thestbobo/DLML_FL_project.git\n",
    "%cd DLML_FL_project"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "id": "mxgzGVP8wLdT",
    "collapsed": true,
    "outputId": "5aad3c43-2a0f-4c68-969a-8825ad501aad",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.19.10)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.6.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.2.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (5.9.5)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (2.11.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (2.27.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 3)) (75.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 3)) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 3)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 3)) (5.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.8/13.8 MB\u001B[0m \u001B[31m126.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.6/24.6 MB\u001B[0m \u001B[31m95.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m883.7/883.7 kB\u001B[0m \u001B[31m56.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m12.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m109.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd DLML_FL_project\n"
   ],
   "metadata": {
    "id": "8im8JrS74eXo",
    "outputId": "d91092ab-3798-47a8-fcdb-20b976fcc604",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: 'DLML_FL_project'\n",
      "/content/DLML_FL_project\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Pull after local commits**"
   ],
   "metadata": {
    "id": "p0A5t1Ds9ze0"
   }
  },
  {
   "cell_type": "code",
   "source": "!git pull origin global_mask_fix\n",
   "metadata": {
    "id": "s67IDKW84fkZ",
    "outputId": "1315c17b-91e6-4ff5-f9ec-b68801872104",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "remote: Enumerating objects: 24, done.\u001B[K\n",
      "remote: Counting objects:   4% (1/24)\u001B[K\rremote: Counting objects:   8% (2/24)\u001B[K\rremote: Counting objects:  12% (3/24)\u001B[K\rremote: Counting objects:  16% (4/24)\u001B[K\rremote: Counting objects:  20% (5/24)\u001B[K\rremote: Counting objects:  25% (6/24)\u001B[K\rremote: Counting objects:  29% (7/24)\u001B[K\rremote: Counting objects:  33% (8/24)\u001B[K\rremote: Counting objects:  37% (9/24)\u001B[K\rremote: Counting objects:  41% (10/24)\u001B[K\rremote: Counting objects:  45% (11/24)\u001B[K\rremote: Counting objects:  50% (12/24)\u001B[K\rremote: Counting objects:  54% (13/24)\u001B[K\rremote: Counting objects:  58% (14/24)\u001B[K\rremote: Counting objects:  62% (15/24)\u001B[K\rremote: Counting objects:  66% (16/24)\u001B[K\rremote: Counting objects:  70% (17/24)\u001B[K\rremote: Counting objects:  75% (18/24)\u001B[K\rremote: Counting objects:  79% (19/24)\u001B[K\rremote: Counting objects:  83% (20/24)\u001B[K\rremote: Counting objects:  87% (21/24)\u001B[K\rremote: Counting objects:  91% (22/24)\u001B[K\rremote: Counting objects:  95% (23/24)\u001B[K\rremote: Counting objects: 100% (24/24)\u001B[K\rremote: Counting objects: 100% (24/24), done.\u001B[K\n",
      "remote: Compressing objects:  10% (1/10)\u001B[K\rremote: Compressing objects:  20% (2/10)\u001B[K\rremote: Compressing objects:  30% (3/10)\u001B[K\rremote: Compressing objects:  40% (4/10)\u001B[K\rremote: Compressing objects:  50% (5/10)\u001B[K\rremote: Compressing objects:  60% (6/10)\u001B[K\rremote: Compressing objects:  70% (7/10)\u001B[K\rremote: Compressing objects:  80% (8/10)\u001B[K\rremote: Compressing objects:  90% (9/10)\u001B[K\rremote: Compressing objects: 100% (10/10)\u001B[K\rremote: Compressing objects: 100% (10/10), done.\u001B[K\n",
      "remote: Total 17 (delta 12), reused 12 (delta 7), pack-reused 0 (from 0)\u001B[K\n",
      "Unpacking objects:   5% (1/17)\rUnpacking objects:  11% (2/17)\rUnpacking objects:  17% (3/17)\rUnpacking objects:  23% (4/17)\rUnpacking objects:  29% (5/17)\rUnpacking objects:  35% (6/17)\rUnpacking objects:  41% (7/17)\rUnpacking objects:  47% (8/17)\rUnpacking objects:  52% (9/17)\rUnpacking objects:  58% (10/17)\rUnpacking objects:  64% (11/17)\rUnpacking objects:  70% (12/17)\rUnpacking objects:  76% (13/17)\rUnpacking objects:  82% (14/17)\rUnpacking objects:  88% (15/17)\rUnpacking objects:  94% (16/17)\rUnpacking objects: 100% (17/17)\rUnpacking objects: 100% (17/17), 1.96 KiB | 400.00 KiB/s, done.\n",
      "From https://github.com/thestbobo/DLML_FL_project\n",
      " * branch            main       -> FETCH_HEAD\n",
      "   d25564d..91fe87f  main       -> origin/main\n",
      "Updating d25564d..91fe87f\n",
      "Fast-forward\n",
      " .idea/misc.xml      |  2 \u001B[32m+\u001B[m\u001B[31m-\u001B[m\n",
      " fl_core/__init__.py |  0\n",
      " requirements.txt    |  3 \u001B[32m++\u001B[m\u001B[31m-\u001B[m\n",
      " train.py            |  2 \u001B[32m+\u001B[m\u001B[31m-\u001B[m\n",
      " train_federated.py  | 28 \u001B[32m++++++++++++++++\u001B[m\u001B[31m------------\u001B[m\n",
      " 5 files changed, 20 insertions(+), 15 deletions(-)\n",
      " delete mode 100644 fl_core/__init__.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Environment check**"
   ],
   "metadata": {
    "id": "Fq6CSsDxFl_c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(\"CUDA avaiable:\", torch.cuda.is_available())"
   ],
   "metadata": {
    "id": "WLGGMmyHFqbr",
    "outputId": "56010f3c-065f-4d79-8e45-52c2c881346a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CUDA avaiable: True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load Configuration (hyperparameters) and Paths (in/out)**\n",
    "\n",
    "-Example file for config.yaml\n",
    "\n",
    "batch_size: 64\n",
    "\n",
    "lr: 0.01\n",
    "\n",
    "-Example of code usage:\n",
    "\n",
    "print(config[\"batch_size\"]) --> 64\n"
   ],
   "metadata": {
    "id": "rufqzKaaF7xs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# load YAML config\n",
    "with open(\"config/config.yaml\") as f:\n",
    "  config = yaml.safe_load(f)\n",
    "\n",
    "# Setup paths and device\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DEVICE= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(config)"
   ],
   "metadata": {
    "id": "KlJG1U1WGeiN",
    "outputId": "faedb8a0-e482-46e2-c9b8-d9dfee30f716",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 256, 'val_split': 0.2, 'num_workers': 4, 'learning_rate': 0.008805, 'weight_decay': 0.01, 'momentum': 0.9, 't_max': 50, 'epochs': 50, 'checkpoint_path': '/content/drive/MyDrive/DL_project/checkpoints/checkpoint_35.pth', 'out_checkpoint_dir': '/content/drive/MyDrive/DL_project/checkpoints', 'NUM_CLIENTS': 100, 'CLIENT_FRACTION': 0.1, 'LOCAL_EPOCHS': 4, 'BATCH_SIZE': 32, 'LR': 0.01, 'ROUNDS': 100, 'IID': True, 'NC': None, 'SEED': 42}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "gzAeGoLJvlqG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training and results visualisazion**"
   ],
   "metadata": {
    "id": "XsshK5U0vqkW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%env WANDB_API_KEY=9efaa9e72ef3b211a9239aed9b1ea7dcb2f680ad"
   ],
   "metadata": {
    "id": "F8Wh8RJTvlRf",
    "outputId": "ee5e2a40-5542-42ad-e331-96d47e70ea93",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: WANDB_API_KEY=9efaa9e72ef3b211a9239aed9b1ea7dcb2f680ad\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "d5e7pzY9RzvE"
   },
   "cell_type": "markdown",
   "source": [
    "The code snippet below runs an already created sweep on the centralized model. If you want to run the sweep yourself and view the results, you need to create a new sweep via terminal, copy the given sweep_id and change it below"
   ]
  },
  {
   "metadata": {
    "id": "cdJ4RF2_RzvE"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import wandb\n",
    "import importlib.util\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# setup sweep function dynamically\n",
    "spec = importlib.util.spec_from_file_location(\"train\", \"/content/DLML_FL_project/train.py\")\n",
    "train_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(train_module)\n",
    "main = train_module.main\n",
    "\n",
    "\n",
    "# my wandb api key\n",
    "%env WANDB_API_KEY=e78d3761af2b7e3a53b7a9ba6385370820743648\n",
    "\n",
    "\n",
    "# run sweep - change here to run it yourself\n",
    "sweep_id = \"s297466-politecnico-di-torino/DLML_FL_project/fx50wubp\"\n",
    "wandb.agent(sweep_id, function=main, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "YQaJ90MzUFXJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "CENTRALIZED"
   ],
   "metadata": {
    "id": "bpNbvj6Rh14I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python train.py"
   ],
   "metadata": {
    "id": "8dzzNjMtv53Y",
    "outputId": "5954c515-87c3-42ba-b7ea-d9e5605ddc25",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device:  cuda\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33ms297466\u001B[0m (\u001B[33ms297466-politecnico-di-torino\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.19.10\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/content/DLML_FL_project/wandb/run-20250501_100731-zble4yuy\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33micy-wood-80\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized/runs/zble4yuy\u001B[0m\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n",
      "Loading checkpoint from /content/drive/MyDrive/DL_project/checkpoints/checkpoint_35.pth ...\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/DLML_FL_project/train.py\", line 177, in <module>\n",
      "    main()\n",
      "  File \"/content/DLML_FL_project/train.py\", line 124, in main\n",
      "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 32, in inner\n",
      "    return disable_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 745, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 880, in load_state_dict\n",
      "    raise ValueError(\n",
      "ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group\n",
      "\u001B[1;34mwandb\u001B[0m: \n",
      "\u001B[1;34mwandb\u001B[0m: 🚀 View run \u001B[33micy-wood-80\u001B[0m at: \u001B[34mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized/runs/zble4yuy\u001B[0m\n",
      "\u001B[1;34mwandb\u001B[0m: Find logs at: \u001B[1;35mwandb/run-20250501_100731-zble4yuy/logs\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "FEDERATED"
   ],
   "metadata": {
    "id": "hPlNZHpJh3nI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python train_federated.py"
   ],
   "metadata": {
    "id": "tP88YoXxh40Y"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
