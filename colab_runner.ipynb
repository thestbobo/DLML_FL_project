{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thestbobo/DLML_FL_project/blob/main/colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Environment Setup**"
   ],
   "metadata": {
    "id": "L51bSihQEz-a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "EkDPMfWpSljA",
    "outputId": "506912a8-2257-4976-a15c-84af542d1b58",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f1EUz3AzEYn9",
    "outputId": "163f3540-6122-4a94-f5d0-3c84e7762caa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'DLML_FL_project'...\n",
      "remote: Enumerating objects: 269, done.\u001B[K\n",
      "remote: Counting objects: 100% (167/167), done.\u001B[K\n",
      "remote: Compressing objects: 100% (100/100), done.\u001B[K\n",
      "remote: Total 269 (delta 94), reused 120 (delta 56), pack-reused 102 (from 1)\u001B[K\n",
      "Receiving objects: 100% (269/269), 67.41 KiB | 556.00 KiB/s, done.\n",
      "Resolving deltas: 100% (129/129), done.\n",
      "/content/DLML_FL_project\n"
     ]
    }
   ],
   "source": [
    "# Clone GitHub repository\n",
    "!git clone https://github.com/thestbobo/DLML_FL_project.git\n",
    "%cd DLML_FL_project\n",
    "# Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "%cd DLML_FL_project"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Pull after local commits**"
   ],
   "metadata": {
    "id": "p0A5t1Ds9ze0"
   }
  },
  {
   "cell_type": "code",
   "source": "!git checkout dense_training\n",
   "metadata": {
    "id": "s67IDKW84fkZ",
    "outputId": "1315c17b-91e6-4ff5-f9ec-b68801872104",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "remote: Enumerating objects: 24, done.\u001B[K\n",
      "remote: Counting objects:   4% (1/24)\u001B[K\rremote: Counting objects:   8% (2/24)\u001B[K\rremote: Counting objects:  12% (3/24)\u001B[K\rremote: Counting objects:  16% (4/24)\u001B[K\rremote: Counting objects:  20% (5/24)\u001B[K\rremote: Counting objects:  25% (6/24)\u001B[K\rremote: Counting objects:  29% (7/24)\u001B[K\rremote: Counting objects:  33% (8/24)\u001B[K\rremote: Counting objects:  37% (9/24)\u001B[K\rremote: Counting objects:  41% (10/24)\u001B[K\rremote: Counting objects:  45% (11/24)\u001B[K\rremote: Counting objects:  50% (12/24)\u001B[K\rremote: Counting objects:  54% (13/24)\u001B[K\rremote: Counting objects:  58% (14/24)\u001B[K\rremote: Counting objects:  62% (15/24)\u001B[K\rremote: Counting objects:  66% (16/24)\u001B[K\rremote: Counting objects:  70% (17/24)\u001B[K\rremote: Counting objects:  75% (18/24)\u001B[K\rremote: Counting objects:  79% (19/24)\u001B[K\rremote: Counting objects:  83% (20/24)\u001B[K\rremote: Counting objects:  87% (21/24)\u001B[K\rremote: Counting objects:  91% (22/24)\u001B[K\rremote: Counting objects:  95% (23/24)\u001B[K\rremote: Counting objects: 100% (24/24)\u001B[K\rremote: Counting objects: 100% (24/24), done.\u001B[K\n",
      "remote: Compressing objects:  10% (1/10)\u001B[K\rremote: Compressing objects:  20% (2/10)\u001B[K\rremote: Compressing objects:  30% (3/10)\u001B[K\rremote: Compressing objects:  40% (4/10)\u001B[K\rremote: Compressing objects:  50% (5/10)\u001B[K\rremote: Compressing objects:  60% (6/10)\u001B[K\rremote: Compressing objects:  70% (7/10)\u001B[K\rremote: Compressing objects:  80% (8/10)\u001B[K\rremote: Compressing objects:  90% (9/10)\u001B[K\rremote: Compressing objects: 100% (10/10)\u001B[K\rremote: Compressing objects: 100% (10/10), done.\u001B[K\n",
      "remote: Total 17 (delta 12), reused 12 (delta 7), pack-reused 0 (from 0)\u001B[K\n",
      "Unpacking objects:   5% (1/17)\rUnpacking objects:  11% (2/17)\rUnpacking objects:  17% (3/17)\rUnpacking objects:  23% (4/17)\rUnpacking objects:  29% (5/17)\rUnpacking objects:  35% (6/17)\rUnpacking objects:  41% (7/17)\rUnpacking objects:  47% (8/17)\rUnpacking objects:  52% (9/17)\rUnpacking objects:  58% (10/17)\rUnpacking objects:  64% (11/17)\rUnpacking objects:  70% (12/17)\rUnpacking objects:  76% (13/17)\rUnpacking objects:  82% (14/17)\rUnpacking objects:  88% (15/17)\rUnpacking objects:  94% (16/17)\rUnpacking objects: 100% (17/17)\rUnpacking objects: 100% (17/17), 1.96 KiB | 400.00 KiB/s, done.\n",
      "From https://github.com/thestbobo/DLML_FL_project\n",
      " * branch            main       -> FETCH_HEAD\n",
      "   d25564d..91fe87f  main       -> origin/main\n",
      "Updating d25564d..91fe87f\n",
      "Fast-forward\n",
      " .idea/misc.xml      |  2 \u001B[32m+\u001B[m\u001B[31m-\u001B[m\n",
      " fl_core/__init__.py |  0\n",
      " requirements.txt    |  3 \u001B[32m++\u001B[m\u001B[31m-\u001B[m\n",
      " train.py            |  2 \u001B[32m+\u001B[m\u001B[31m-\u001B[m\n",
      " train_federated.py  | 28 \u001B[32m++++++++++++++++\u001B[m\u001B[31m------------\u001B[m\n",
      " 5 files changed, 20 insertions(+), 15 deletions(-)\n",
      " delete mode 100644 fl_core/__init__.py\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Environment check**"
   ],
   "metadata": {
    "id": "Fq6CSsDxFl_c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(\"CUDA avaiable:\", torch.cuda.is_available())"
   ],
   "metadata": {
    "id": "WLGGMmyHFqbr",
    "outputId": "56010f3c-065f-4d79-8e45-52c2c881346a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CUDA avaiable: True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load Configuration (hyperparameters) and Paths (in/out)**\n",
    "\n",
    "-Example file for config.yaml\n",
    "\n",
    "batch_size: 64\n",
    "\n",
    "lr: 0.01\n",
    "\n",
    "-Example of code usage:\n",
    "\n",
    "print(config[\"batch_size\"]) --> 64\n"
   ],
   "metadata": {
    "id": "rufqzKaaF7xs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# load YAML config\n",
    "with open(\"config/config.yaml\") as f:\n",
    "  config = yaml.safe_load(f)\n",
    "\n",
    "# Setup paths and device\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DEVICE= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(config)"
   ],
   "metadata": {
    "id": "KlJG1U1WGeiN",
    "outputId": "faedb8a0-e482-46e2-c9b8-d9dfee30f716",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 256, 'val_split': 0.2, 'num_workers': 4, 'learning_rate': 0.008805, 'weight_decay': 0.01, 'momentum': 0.9, 't_max': 50, 'epochs': 50, 'checkpoint_path': '/content/drive/MyDrive/DL_project/checkpoints/checkpoint_35.pth', 'out_checkpoint_dir': '/content/drive/MyDrive/DL_project/checkpoints', 'NUM_CLIENTS': 100, 'CLIENT_FRACTION': 0.1, 'LOCAL_EPOCHS': 4, 'BATCH_SIZE': 32, 'LR': 0.01, 'ROUNDS': 100, 'IID': True, 'NC': None, 'SEED': 42}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "gzAeGoLJvlqG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training and results visualisazion**"
   ],
   "metadata": {
    "id": "XsshK5U0vqkW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%env WANDB_API_KEY=9efaa9e72ef3b211a9239aed9b1ea7dcb2f680ad"
   ],
   "metadata": {
    "id": "F8Wh8RJTvlRf",
    "outputId": "ee5e2a40-5542-42ad-e331-96d47e70ea93",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: WANDB_API_KEY=9efaa9e72ef3b211a9239aed9b1ea7dcb2f680ad\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "d5e7pzY9RzvE"
   },
   "cell_type": "markdown",
   "source": [
    "The code snippet below runs an already created sweep on the centralized model. If you want to run the sweep yourself and view the results, you need to create a new sweep via terminal, copy the given sweep_id and change it below"
   ]
  },
  {
   "metadata": {
    "id": "cdJ4RF2_RzvE"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import wandb\n",
    "import importlib.util\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# setup sweep function dynamically\n",
    "spec = importlib.util.spec_from_file_location(\"train\", \"/content/DLML_FL_project/train.py\")\n",
    "train_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(train_module)\n",
    "main = train_module.main\n",
    "\n",
    "\n",
    "# my wandb api key\n",
    "%env WANDB_API_KEY=e78d3761af2b7e3a53b7a9ba6385370820743648\n",
    "\n",
    "\n",
    "# run sweep - change here to run it yourself\n",
    "sweep_id = \"atabaycetin-politecnico-di-torino/DLML_FL_project/tebuexzs\"\n",
    "wandb.agent(sweep_id, function=main, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "YQaJ90MzUFXJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "CENTRALIZED"
   ],
   "metadata": {
    "id": "bpNbvj6Rh14I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python train.py"
   ],
   "metadata": {
    "id": "8dzzNjMtv53Y",
    "outputId": "5954c515-87c3-42ba-b7ea-d9e5605ddc25",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device:  cuda\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33ms297466\u001B[0m (\u001B[33ms297466-politecnico-di-torino\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.19.10\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/content/DLML_FL_project/wandb/run-20250501_100731-zble4yuy\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33micy-wood-80\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized/runs/zble4yuy\u001B[0m\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n",
      "Loading checkpoint from /content/drive/MyDrive/DL_project/checkpoints/checkpoint_35.pth ...\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/DLML_FL_project/train.py\", line 177, in <module>\n",
      "    main()\n",
      "  File \"/content/DLML_FL_project/train.py\", line 124, in main\n",
      "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 32, in inner\n",
      "    return disable_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 745, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 880, in load_state_dict\n",
      "    raise ValueError(\n",
      "ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group\n",
      "\u001B[1;34mwandb\u001B[0m: \n",
      "\u001B[1;34mwandb\u001B[0m: 🚀 View run \u001B[33micy-wood-80\u001B[0m at: \u001B[34mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized/runs/zble4yuy\u001B[0m\n",
      "\u001B[1;34mwandb\u001B[0m: Find logs at: \u001B[1;35mwandb/run-20250501_100731-zble4yuy/logs\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "FEDERATED"
   ],
   "metadata": {
    "id": "hPlNZHpJh3nI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python train_federated.py"
   ],
   "metadata": {
    "id": "tP88YoXxh40Y"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
