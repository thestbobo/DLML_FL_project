{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thestbobo/DLML_FL_project/blob/modularizing-mask-computation/colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L51bSihQEz-a"
   },
   "source": [
    "**Environment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkDPMfWpSljA",
    "outputId": "506912a8-2257-4976-a15c-84af542d1b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "f1EUz3AzEYn9",
    "outputId": "163f3540-6122-4a94-f5d0-3c84e7762caa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DLML_FL_project'...\n",
      "remote: Enumerating objects: 269, done.\u001b[K\n",
      "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
      "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
      "remote: Total 269 (delta 94), reused 120 (delta 56), pack-reused 102 (from 1)\u001b[K\n",
      "Receiving objects: 100% (269/269), 67.41 KiB | 556.00 KiB/s, done.\n",
      "Resolving deltas: 100% (129/129), done.\n",
      "/content/DLML_FL_project\n"
     ]
    }
   ],
   "source": [
    "# Clone GitHub repository\n",
    "!git clone -b modularizing-mask-computation https://github.com/thestbobo/DLML_FL_project.git\n",
    "%cd DLML_FL_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "mxgzGVP8wLdT",
    "outputId": "5aad3c43-2a0f-4c68-969a-8825ad501aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: wandb in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.19.9)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (4.66.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.6.1)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision->-r requirements.txt (line 2)) (10.4.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (5.9.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (2.26.1)\n",
      "Requirement already satisfied: setproctitle in /opt/anaconda3/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 3)) (1.3.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 3)) (4.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3->wandb->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3->wandb->-r requirements.txt (line 3)) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 3)) (4.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8im8JrS74eXo",
    "outputId": "d91092ab-3798-47a8-fcdb-20b976fcc604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'DLML_FL_project'\n",
      "/content/DLML_FL_project\n"
     ]
    }
   ],
   "source": [
    "%cd DLML_FL_project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0A5t1Ds9ze0"
   },
   "source": [
    "**Pull after local commits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s67IDKW84fkZ",
    "outputId": "1315c17b-91e6-4ff5-f9ec-b68801872104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 24, done.\u001b[K\n",
      "remote: Counting objects:   4% (1/24)\u001b[K\rremote: Counting objects:   8% (2/24)\u001b[K\rremote: Counting objects:  12% (3/24)\u001b[K\rremote: Counting objects:  16% (4/24)\u001b[K\rremote: Counting objects:  20% (5/24)\u001b[K\rremote: Counting objects:  25% (6/24)\u001b[K\rremote: Counting objects:  29% (7/24)\u001b[K\rremote: Counting objects:  33% (8/24)\u001b[K\rremote: Counting objects:  37% (9/24)\u001b[K\rremote: Counting objects:  41% (10/24)\u001b[K\rremote: Counting objects:  45% (11/24)\u001b[K\rremote: Counting objects:  50% (12/24)\u001b[K\rremote: Counting objects:  54% (13/24)\u001b[K\rremote: Counting objects:  58% (14/24)\u001b[K\rremote: Counting objects:  62% (15/24)\u001b[K\rremote: Counting objects:  66% (16/24)\u001b[K\rremote: Counting objects:  70% (17/24)\u001b[K\rremote: Counting objects:  75% (18/24)\u001b[K\rremote: Counting objects:  79% (19/24)\u001b[K\rremote: Counting objects:  83% (20/24)\u001b[K\rremote: Counting objects:  87% (21/24)\u001b[K\rremote: Counting objects:  91% (22/24)\u001b[K\rremote: Counting objects:  95% (23/24)\u001b[K\rremote: Counting objects: 100% (24/24)\u001b[K\rremote: Counting objects: 100% (24/24), done.\u001b[K\n",
      "remote: Compressing objects:  10% (1/10)\u001b[K\rremote: Compressing objects:  20% (2/10)\u001b[K\rremote: Compressing objects:  30% (3/10)\u001b[K\rremote: Compressing objects:  40% (4/10)\u001b[K\rremote: Compressing objects:  50% (5/10)\u001b[K\rremote: Compressing objects:  60% (6/10)\u001b[K\rremote: Compressing objects:  70% (7/10)\u001b[K\rremote: Compressing objects:  80% (8/10)\u001b[K\rremote: Compressing objects:  90% (9/10)\u001b[K\rremote: Compressing objects: 100% (10/10)\u001b[K\rremote: Compressing objects: 100% (10/10), done.\u001b[K\n",
      "remote: Total 17 (delta 12), reused 12 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects:   5% (1/17)\rUnpacking objects:  11% (2/17)\rUnpacking objects:  17% (3/17)\rUnpacking objects:  23% (4/17)\rUnpacking objects:  29% (5/17)\rUnpacking objects:  35% (6/17)\rUnpacking objects:  41% (7/17)\rUnpacking objects:  47% (8/17)\rUnpacking objects:  52% (9/17)\rUnpacking objects:  58% (10/17)\rUnpacking objects:  64% (11/17)\rUnpacking objects:  70% (12/17)\rUnpacking objects:  76% (13/17)\rUnpacking objects:  82% (14/17)\rUnpacking objects:  88% (15/17)\rUnpacking objects:  94% (16/17)\rUnpacking objects: 100% (17/17)\rUnpacking objects: 100% (17/17), 1.96 KiB | 400.00 KiB/s, done.\n",
      "From https://github.com/thestbobo/DLML_FL_project\n",
      " * branch            main       -> FETCH_HEAD\n",
      "   d25564d..91fe87f  main       -> origin/main\n",
      "Updating d25564d..91fe87f\n",
      "Fast-forward\n",
      " .idea/misc.xml      |  2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " fl_core/__init__.py |  0\n",
      " requirements.txt    |  3 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
      " train.py            |  2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " train_federated.py  | 28 \u001b[32m++++++++++++++++\u001b[m\u001b[31m------------\u001b[m\n",
      " 5 files changed, 20 insertions(+), 15 deletions(-)\n",
      " delete mode 100644 fl_core/__init__.py\n"
     ]
    }
   ],
   "source": [
    "!git pull origin modularizing-mask-computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fq6CSsDxFl_c"
   },
   "source": [
    "**Environment check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLGGMmyHFqbr",
    "outputId": "56010f3c-065f-4d79-8e45-52c2c881346a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA avaiable: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA avaiable:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rufqzKaaF7xs"
   },
   "source": [
    "**Load Configuration (hyperparameters) and Paths (in/out)**\n",
    "\n",
    "-Example file for config.yaml\n",
    "\n",
    "batch_size: 64\n",
    "\n",
    "lr: 0.01\n",
    "\n",
    "-Example of code usage:\n",
    "\n",
    "print(config[\"batch_size\"]) --> 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlJG1U1WGeiN",
    "outputId": "faedb8a0-e482-46e2-c9b8-d9dfee30f716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'val_split': 0.2, 'num_workers': 4, 'learning_rate': 0.008805, 'weight_decay': 0.01, 'momentum': 0.9, 't_max': 50, 'epochs': 50, 'checkpoint_path': '/content/drive/MyDrive/DL_project/checkpoints/checkpoint_35.pth', 'out_checkpoint_dir': '/content/drive/MyDrive/DL_project/checkpoints', 'NUM_CLIENTS': 100, 'CLIENT_FRACTION': 0.1, 'LOCAL_EPOCHS': 4, 'BATCH_SIZE': 32, 'LR': 0.01, 'ROUNDS': 100, 'IID': True, 'NC': None, 'SEED': 42}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# load YAML config\n",
    "with open(\"config/config.yaml\") as f:\n",
    "  config = yaml.safe_load(f)\n",
    "\n",
    "# Setup paths and device\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DEVICE= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzAeGoLJvlqG"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsshK5U0vqkW"
   },
   "source": [
    "**Training and results visualisazion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8Wh8RJTvlRf",
    "outputId": "ee5e2a40-5542-42ad-e331-96d47e70ea93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_API_KEY=9efaa9e72ef3b211a9239aed9b1ea7dcb2f680ad\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_API_KEY=9efaa9e72ef3b211a9239aed9b1ea7dcb2f680ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5e7pzY9RzvE"
   },
   "source": [
    "The code snippet below runs an already created sweep on the centralized model. If you want to run the sweep yourself and view the results, you need to create a new sweep via terminal, copy the given sweep_id and change it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdJ4RF2_RzvE"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import importlib.util\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# setup sweep function dynamically\n",
    "spec = importlib.util.spec_from_file_location(\"train\", \"/content/DLML_FL_project/train.py\")\n",
    "train_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(train_module)\n",
    "main = train_module.main\n",
    "\n",
    "\n",
    "# my wandb api key\n",
    "%env WANDB_API_KEY=e78d3761af2b7e3a53b7a9ba6385370820743648\n",
    "\n",
    "\n",
    "# run sweep - change here to run it yourself\n",
    "sweep_id = \"s297466-politecnico-di-torino/DLML_FL_project/fx50wubp\"\n",
    "wandb.agent(sweep_id, function=main, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQaJ90MzUFXJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpNbvj6Rh14I"
   },
   "source": [
    "CENTRALIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dzzNjMtv53Y",
    "outputId": "5954c515-87c3-42ba-b7ea-d9e5605ddc25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms297466\u001b[0m (\u001b[33ms297466-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/DLML_FL_project/wandb/run-20250501_100731-zble4yuy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33micy-wood-80\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized/runs/zble4yuy\u001b[0m\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n",
      "Loading checkpoint from /content/drive/MyDrive/DL_project/checkpoints/checkpoint_35.pth ...\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/DLML_FL_project/train.py\", line 177, in <module>\n",
      "    main()\n",
      "  File \"/content/DLML_FL_project/train.py\", line 124, in main\n",
      "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_compile.py\", line 32, in inner\n",
      "    return disable_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\", line 745, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 880, in load_state_dict\n",
      "    raise ValueError(\n",
      "ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33micy-wood-80\u001b[0m at: \u001b[34mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized/runs/zble4yuy\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250501_100731-zble4yuy/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPlNZHpJh3nI"
   },
   "source": [
    "FEDERATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tP88YoXxh40Y"
   },
   "outputs": [],
   "source": [
    "!python train_federated.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
